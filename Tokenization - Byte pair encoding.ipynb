{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc82a8be-66bc-4c93-b6c0-3ac32b676881",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the tiktoken library to:\n",
    "1) Encode text into tokens (integers) using the tokenization scheme of a specific model (gpt2 in this case).\n",
    "2) Decode those tokens back to text.\n",
    "This is useful for understanding how language models handle text in its tokenized form, which is essential for tasks like text generation or semantic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d310d-f081-4860-9efe-62d5fc71e72b",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- openai-cookbook\n",
    "- Build a Large Language Model (From Scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da774225-e7c0-4c95-8a6a-58fbb31faae7",
   "metadata": {},
   "source": [
    "Byte Pair Encoding (BPE)\n",
    "-----------\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620f158-b419-498d-9fa9-c66df2cf754f",
   "metadata": {},
   "source": [
    "Byte Pair Encoding (BPE) is a compression and tokenization algorithm widely used in language models, such as those used to program chatbots. Essentially, BPE allows text to be represented as a combination of subwords or fragments, optimizing both vocabulary and the handling of new words.\n",
    "\n",
    "Purpose of BPE in Chatbots:\n",
    "---------------------------\n",
    "BPE is used to:\n",
    "\n",
    "- Reduce vocabulary size: Instead of treating each word as a separate unit, break words into smaller subunits (subwords, letters, or common fragments).\n",
    "- Handle Out-of-Vocabulary (OOV) Words: Even if a word is not in the vocabulary, it can be represented by its subunits, allowing the model to handle unknown text more flexibly.\n",
    "- Optimize performance: A smaller vocabulary reduces the computational complexity of the model.\n",
    "\n",
    "How BPE Works:\n",
    "--------\n",
    "\n",
    "**Initialization:** it starts with a vocabulary that contains all the individual characters present in the training text, plus some special tokens (such as <|endoftext|>).\n",
    "\n",
    "**Creating frequent combinations:** the pair of symbols (characters or sequences) that appears most frequently in the text is identified. These pairs are merged to form a new token.\n",
    "\n",
    "**Repetition of the process:** the process is repeated a fixed number of times or until a predefined vocabulary size is reached.\n",
    "\n",
    "**Generation of the final vocabulary:** the vocabulary contains tokens that represent the most frequent subunits in the training text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eac19f-40f5-46f6-86cb-138589eefc4e",
   "metadata": {},
   "source": [
    "Practical Implementation\n",
    "-----------\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5bf441e-4a13-4823-ba13-affb2a1f208e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "     -------------------------------------- 884.2/884.2 kB 8.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\brods\\anaconda3\\lib\\site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\brods\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brods\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brods\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\brods\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\brods\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e39fd-8796-4308-bd0a-2e9d54aa3b4b",
   "metadata": {},
   "source": [
    "We import \"Version\" from the \"importlib.metadata\" module to obtain the installed version of the tiktoken library. Then we print the version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c68fc4-81f8-4802-8268-bbd34e30ae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88751943-b147-4787-938f-9b186bf51b19",
   "metadata": {},
   "source": [
    "tiktoken.get_encoding is used to get the text tokenizer associated with the gpt2 model. This indicates that the code will use the token encoding scheme used in that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf5810d-6793-4f05-9228-f0715a2ef907",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c3886-53ec-4c55-8b25-869a18695a66",
   "metadata": {},
   "source": [
    "We use some sample text to check how the \"enconde\" and \"decode\" functions work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971c1e88-ce65-46d6-a0c5-1bb3779fb188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    " \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    " \"of someunknownPlace.\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d06dd27-3301-412c-b51c-1261f9f4a5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f7892-bd4d-4b16-9117-01e853395f23",
   "metadata": {},
   "source": [
    "Byte pair encoding of unknown words\n",
    "-----------\n",
    "We can try the BPE tokenizer from the tiktoken library on the unknown words “Akwirw ier” and print the individual token IDs. Then, call the decode function on each of the resulting integers in this list. Lastly, call the decode method on the token IDs to check whether it can reconstruct the original input, “Akwirw ier.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4621035-098c-4771-9efd-c99273d574de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Akwirw ier.\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529f3dcb-3725-4074-addf-be44bb6a5963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akwirw ier.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00095481-518a-4b54-a94f-b98c18512361",
   "metadata": {},
   "source": [
    "Count tokens in text\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99c66a9-d94c-418b-81e1-fcbe8d777a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100084f3-6c99-48ef-9b47-00259ec5deb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(\"tiktoken is great!\", \"o200k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bf93d-6de5-4e25-b10d-99b90fba7531",
   "metadata": {},
   "source": [
    "Turn tokens into text\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf77ea8-8ed4-473d-9434-b734632a1d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akwirw ier.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.get_encoding(\"r50k_base\")\n",
    "encoding.decode([33901, 86, 343, 86, 220, 959, 13])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
